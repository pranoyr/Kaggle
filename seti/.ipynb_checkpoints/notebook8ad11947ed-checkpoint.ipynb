{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4d810ab9-c9c5-4a26-9739-debe5543c28e",
    "_uuid": "5e52fec7-9979-4b7e-851b-418d406b248b",
    "execution": {
     "iopub.execute_input": "2021-06-07T16:34:01.055135Z",
     "iopub.status.busy": "2021-06-07T16:34:01.054782Z",
     "iopub.status.idle": "2021-06-07T16:34:01.065799Z",
     "shell.execute_reply": "2021-06-07T16:34:01.06463Z",
     "shell.execute_reply.started": "2021-06-07T16:34:01.055101Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils import data\n",
    "import torch\n",
    "\n",
    "\n",
    "# train_annot = pd.read_csv(train_dir)\n",
    "# train_annot = train_annot.values.tolist()\n",
    "# print(train_annot[0])\n",
    "# print(os.listdir(f\"{root_dir}/0\"))\n",
    "\n",
    "\n",
    "def make_dataset(csv_file):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    data = data.values.tolist()\n",
    "    return data\n",
    "\n",
    "\n",
    "class SETIDataset(data.Dataset):\n",
    "\t'Characterizes a dataset for PyTorch'\n",
    "\n",
    "\tdef __init__(self, root_dir, csv_file, num_classes=2, transform=None):\n",
    "\t\t'Initialization'\n",
    "\t\tself.root_dir = root_dir\n",
    "\t\tself.transform = transform\n",
    "\t\tself.num_classes = num_classes\n",
    "\n",
    "\t\tself.data = make_dataset(csv_file)\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\t'Denotes the total number of samples'\n",
    "\t\treturn len(self.data)\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\t'Generates one sample of data'\n",
    "\t\t# ---- Get Inputs ----\n",
    "\t\tx = np.load(f\"{self.root_dir}/{self.data[index][0][0]}/{self.data[index][0]}.npy\")\n",
    "\t\tx = self.transform(torch.from_numpy(x))\n",
    "\n",
    "\t\t# ---- Get Labels ----\n",
    "\t\tlabel = self.data[index][1]\n",
    "\t\ttarget = torch.tensor(label)\n",
    "\t\treturn x.type(torch.FloatTensor), target.type(torch.LongTensor)\n",
    "\n",
    "\n",
    "# root_dir = '/kaggle/input/seti-breakthrough-listen/train'\n",
    "# train_csv = '/kaggle/input/seti-breakthrough-listen/train_labels.csv'\n",
    "# a = SETIDataset(root_dir, train_csv)\n",
    "# print(a.__getitem__(0)[0].shape)\n",
    "\n",
    "        \n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a241c0b3-d580-4c82-8203-c37dd3a7d22f",
    "_uuid": "f05e3006-1b80-45d9-951d-cd5f2642591d",
    "execution": {
     "iopub.execute_input": "2021-06-07T16:34:01.067736Z",
     "iopub.status.busy": "2021-06-07T16:34:01.067357Z",
     "iopub.status.idle": "2021-06-07T16:34:01.093492Z",
     "shell.execute_reply": "2021-06-07T16:34:01.092444Z",
     "shell.execute_reply.started": "2021-06-07T16:34:01.0677Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# tensor([ 1.1921e-06,  2.3842e-07,  1.2517e-06,  1.7881e-07,  1.4305e-06,\n",
    "#         -1.1921e-07], device='cuda:0', dtype=torch.float16)\n",
    "# tensor([0.0408, 0.0408, 0.0408, 0.0408, 0.0408, 0.0408], device='cuda:0',\n",
    "#        dtype=torch.float16)\n",
    "\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicConv(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n",
    "        super(BasicConv, self).__init__()\n",
    "        self.out_channels = out_planes\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(out_planes,eps=1e-5, momentum=0.01, affine=True) if bn else None\n",
    "        self.relu = nn.ReLU() if relu else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.relu is not None:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ChannelGate(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max']):\n",
    "        super(ChannelGate, self).__init__()\n",
    "        self.gate_channels = gate_channels\n",
    "        self.mlp = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Linear(gate_channels, gate_channels // reduction_ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(gate_channels // reduction_ratio, gate_channels)\n",
    "            )\n",
    "        self.pool_types = pool_types\n",
    "    def forward(self, x):\n",
    "        channel_att_sum = None\n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type=='avg':\n",
    "                avg_pool = F.avg_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( avg_pool )\n",
    "            elif pool_type=='max':\n",
    "                max_pool = F.max_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( max_pool )\n",
    "            elif pool_type=='lp':\n",
    "                lp_pool = F.lp_pool2d( x, 2, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( lp_pool )\n",
    "            elif pool_type=='lse':\n",
    "                # LSE pool only\n",
    "                lse_pool = logsumexp_2d(x)\n",
    "                channel_att_raw = self.mlp( lse_pool )\n",
    "\n",
    "            if channel_att_sum is None:\n",
    "                channel_att_sum = channel_att_raw\n",
    "            else:\n",
    "                channel_att_sum = channel_att_sum + channel_att_raw\n",
    "\n",
    "        scale = F.sigmoid( channel_att_sum ).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "        return x * scale\n",
    "\n",
    "def logsumexp_2d(tensor):\n",
    "    tensor_flatten = tensor.view(tensor.size(0), tensor.size(1), -1)\n",
    "    s, _ = torch.max(tensor_flatten, dim=2, keepdim=True)\n",
    "    outputs = s + (tensor_flatten - s).exp().sum(dim=2, keepdim=True).log()\n",
    "    return outputs\n",
    "\n",
    "class ChannelPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )\n",
    "\n",
    "class SpatialGate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialGate, self).__init__()\n",
    "        kernel_size = 7\n",
    "        self.compress = ChannelPool()\n",
    "        self.spatial = BasicConv(2, 1, kernel_size, stride=1, padding=(kernel_size-1) // 2, relu=False)\n",
    "    def forward(self, x):\n",
    "        x_compress = self.compress(x)\n",
    "        x_out = self.spatial(x_compress)\n",
    "        scale = F.sigmoid(x_out) # broadcasting\n",
    "        return x * scale\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max'], no_spatial=False):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.ChannelGate = ChannelGate(gate_channels, reduction_ratio, pool_types)\n",
    "        self.no_spatial=no_spatial\n",
    "        if not no_spatial:\n",
    "            self.SpatialGate = SpatialGate()\n",
    "    def forward(self, x):\n",
    "        x_out = self.ChannelGate(x)\n",
    "        if not self.no_spatial:\n",
    "            x_out = self.SpatialGate(x_out)\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "51deba35-f15f-43b2-9be0-3539e69e8d7c",
    "_uuid": "5fe887fe-ebf9-4497-baf3-e411b3a8c230",
    "execution": {
     "iopub.execute_input": "2021-06-07T16:34:01.174288Z",
     "iopub.status.busy": "2021-06-07T16:34:01.174036Z",
     "iopub.status.idle": "2021-06-07T16:34:03.689593Z",
     "shell.execute_reply": "2021-06-07T16:34:03.688577Z",
     "shell.execute_reply.started": "2021-06-07T16:34:01.174265Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.nn import init\n",
    "# from bam import *\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_cbam=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "        if use_cbam:\n",
    "            self.cbam = CBAM( planes, 16 )\n",
    "        else:\n",
    "            self.cbam = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        if not self.cbam is None:\n",
    "            out = self.cbam(out)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_cbam=False):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "        if use_cbam:\n",
    "            self.cbam = CBAM( planes * 4, 16 )\n",
    "        else:\n",
    "            self.cbam = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        if not self.cbam is None:\n",
    "            out = self.cbam(out)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers,  network_type, num_classes, att_type=None):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.network_type = network_type\n",
    "        # different model config between ImageNet and CIFAR \n",
    "        if network_type == \"ImageNet\":\n",
    "            self.conv1 = nn.Conv2d(6, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "            self.avgpool = nn.AvgPool2d(7)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        if att_type=='BAM':\n",
    "            self.bam1 = BAM(64*block.expansion)\n",
    "            self.bam2 = BAM(128*block.expansion)\n",
    "            self.bam3 = BAM(256*block.expansion)\n",
    "        else:\n",
    "            self.bam1, self.bam2, self.bam3 = None, None, None\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64,  layers[0], att_type=att_type)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, att_type=att_type)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, att_type=att_type)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, att_type=att_type)\n",
    "\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        init.kaiming_normal(self.fc.weight)\n",
    "        for key in self.state_dict():\n",
    "            if key.split('.')[-1]==\"weight\":\n",
    "                if \"conv\" in key:\n",
    "                    init.kaiming_normal(self.state_dict()[key], mode='fan_out')\n",
    "                if \"bn\" in key:\n",
    "                    if \"SpatialGate\" in key:\n",
    "                        self.state_dict()[key][...] = 0\n",
    "                    else:\n",
    "                        self.state_dict()[key][...] = 1\n",
    "            elif key.split(\".\")[-1]=='bias':\n",
    "                self.state_dict()[key][...] = 0\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, att_type=None):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, use_cbam=att_type=='CBAM'))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, use_cbam=att_type=='CBAM'))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        if self.network_type == \"ImageNet\":\n",
    "            x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        if not self.bam1 is None:\n",
    "            x = self.bam1(x)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "        if not self.bam2 is None:\n",
    "            x = self.bam2(x)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        if not self.bam3 is None:\n",
    "            x = self.bam3(x)\n",
    "\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        if self.network_type == \"ImageNet\":\n",
    "            x = self.avgpool(x)\n",
    "        else:\n",
    "            x = F.avg_pool2d(x, 4)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def ResidualNet(network_type, depth, num_classes, att_type):\n",
    "\n",
    "    assert network_type in [\"ImageNet\", \"CIFAR10\", \"CIFAR100\"], \"network type should be ImageNet or CIFAR10 / CIFAR100\"\n",
    "    assert depth in [18, 34, 50, 101], 'network depth should be 18, 34, 50 or 101'\n",
    "\n",
    "    if depth == 18:\n",
    "        model = ResNet(BasicBlock, [2, 2, 2, 2], network_type, num_classes, att_type)\n",
    "\n",
    "    elif depth == 34:\n",
    "        model = ResNet(BasicBlock, [3, 4, 6, 3], network_type, num_classes, att_type)\n",
    "\n",
    "    elif depth == 50:\n",
    "        model = ResNet(Bottleneck, [3, 4, 6, 3], network_type, num_classes, att_type)\n",
    "\n",
    "    elif depth == 101:\n",
    "        model = ResNet(Bottleneck, [3, 4, 23, 3], network_type, num_classes, att_type)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "if (__name__=='__main__'):\n",
    "    net = ResidualNet(\"ImageNet\", 18, 2, att_type='CBAM')\n",
    "    x  = torch.randn(32, 6, 224,224)\n",
    "    output = net(x)\n",
    "    print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T16:34:03.691795Z",
     "iopub.status.busy": "2021-06-07T16:34:03.691444Z",
     "iopub.status.idle": "2021-06-07T16:34:03.706595Z",
     "shell.execute_reply": "2021-06-07T16:34:03.705819Z",
     "shell.execute_reply.started": "2021-06-07T16:34:03.691759Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "    \n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T16:34:03.710514Z",
     "iopub.status.busy": "2021-06-07T16:34:03.710265Z",
     "iopub.status.idle": "2021-06-07T16:34:03.721252Z",
     "shell.execute_reply": "2021-06-07T16:34:03.720232Z",
     "shell.execute_reply.started": "2021-06-07T16:34:03.710492Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, criterion, optimizer, epoch, device):\n",
    "   \n",
    "\tmodel.train()\n",
    "\t\n",
    "\tlosses = AverageMeter('Loss', ':.4e')\n",
    "\taccuracies = AverageMeter('Acc', ':6.2f')\n",
    "\tprogress = ProgressMeter(\n",
    "        len(data_loader),\n",
    "        [losses, accuracies],\n",
    "        prefix='Train: ')\n",
    "\t# Training\n",
    "\tfor batch_idx, (data, targets) in enumerate(data_loader):\n",
    "\t\t# compute outputs\n",
    "\t\tdata, targets = data.to(device), targets.to(device)\n",
    "\n",
    "\t\toutputs =  model(data)\n",
    "\t\tloss = criterion(outputs, targets)\n",
    "\n",
    "\t\tacc = accuracy(outputs, targets)\n",
    "\t\tlosses.update(loss.item(), data.size(0))\n",
    "\t\taccuracies.update(acc[0].item(),  data.size(0))\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\t# show information\n",
    "\t\tif batch_idx % 10 == 0:\n",
    "\t\t\tprogress.display(batch_idx)\n",
    "\t\t\n",
    "\t# show information\n",
    "\tprint(f' * Train Loss {losses.avg:.3f}, Train Acc {accuracies.avg:.3f}')\n",
    "\treturn losses.avg, accuracies.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "859e148d-464e-4405-aa64-4d032677d9e7",
    "_uuid": "9b315fec-7b77-4cd9-885f-1f4c5d6c88b3",
    "execution": {
     "iopub.execute_input": "2021-06-07T16:34:03.724688Z",
     "iopub.status.busy": "2021-06-07T16:34:03.724416Z",
     "iopub.status.idle": "2021-06-07T16:40:40.912994Z",
     "shell.execute_reply": "2021-06-07T16:40:40.911034Z",
     "shell.execute_reply.started": "2021-06-07T16:34:03.724664Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.models import resnet18\n",
    "import argparse\n",
    "import tensorboardX\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "resume_path = None\n",
    "start_epoch = 1\n",
    "wt_decay = 0.00001\n",
    "batch_size = 32\n",
    "root_dir = '/kaggle/input/seti-breakthrough-listen/train'\n",
    "train_csv = '/kaggle/input/seti-breakthrough-listen/train_labels.csv'\n",
    "\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "\ttransforms.Normalize(mean=[ 1.1921e-06,  2.3842e-07,  1.2517e-06,  1.7881e-07,  1.4305e-06,\n",
    "\t\t-1.1921e-07], std=[0.0408, 0.0408, 0.0408, 0.0408, 0.0408, 0.0408])\n",
    "])\n",
    "\n",
    "training_data = SETIDataset(root_dir, train_csv, transform=transform)\n",
    "# validation_data = get_validation_set(opt, test_transform)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(training_data,\n",
    "\t\t\t\t\t\t\t\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\t\t\t\t\t\t\t\tshuffle=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\tnum_workers=0)\n",
    "# val_loader = torch.utils.data.DataLoader(validation_data,\n",
    "# \t\t\t\t\t\t\t\t\t\t batch_size=batch_size,\n",
    "# \t\t\t\t\t\t\t\t\t\t shuffle=True,\n",
    "# \t\t\t\t\t\t\t\t\t\t num_workers=0)\n",
    "print(f'Number of training examples: {len(train_loader.dataset)}')\n",
    "# print(f'Number of validation examples: {len(val_loader.dataset)}')\n",
    "\n",
    "# tensorboard\n",
    "summary_writer = tensorboardX.SummaryWriter(log_dir='tf_logs')\n",
    "# define model\n",
    "model = ResidualNet(\"ImageNet\", 101, 2, \"CBAM\")\n",
    "if resume_path:\n",
    "\tcheckpoint = torch.load(resume_path)\n",
    "\tmodel.load_state_dict(checkpoint['model_state_dict'])\n",
    "\tepoch = checkpoint['epoch']\n",
    "\tprint(\"Model Restored from Epoch {}\".format(epoch))\n",
    "\tstart_epoch = epoch + 1\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), weight_decay=wt_decay)\n",
    "# scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=opt.lr_patience)\n",
    "\n",
    "th = 100000\n",
    "# start training\n",
    "for epoch in range(start_epoch, 100):\n",
    "\t# train, test model\n",
    "\ttrain_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, epoch, device)\n",
    "\t# val_loss, val_acc = val_epoch(model, val_loader, criterion, device, opt)\n",
    "\t# #scheduler.step(val_loss)\n",
    "\n",
    "\tlr = optimizer.param_groups[0]['lr']  \n",
    "\t\n",
    "\t# saving weights to checkpoint\n",
    "\tif (epoch) % 10 == 0:\n",
    "\t\t# write summary\n",
    "\t\tsummary_writer.add_scalar(\n",
    "\t\t\t'losses/train_loss', train_loss, global_step=epoch)\n",
    "\t\t# summary_writer.add_scalar(\n",
    "\t\t# \t'losses/val_loss', val_loss, global_step=epoch)\n",
    "\t\tsummary_writer.add_scalar(\n",
    "\t\t\t'acc/train_acc', train_acc, global_step=epoch)\n",
    "\t\t# summary_writer.add_scalar(\n",
    "\t\t# \t'acc/val_acc', val_acc, global_step=epoch)\n",
    "\t\tsummary_writer.add_scalar(\n",
    "\t\t\t'lr_rate', lr, global_step=epoch)\n",
    "\n",
    "\t\t# state = {'epoch': epoch, 'model_state_dict': model.state_dict(),\n",
    "\t\t# \t\t'optimizer_state_dict': optimizer.state_dict(), 'scheduler_state_dict':scheduler.state_dict()}\n",
    "\t\t# if val_loss < th:\n",
    "\t\t# \ttorch.save(state, os.path.join('./snapshots', 'ensemble-model.pth'))\n",
    "\t\t# \tprint(\"Epoch {} model saved!\\n\".format(epoch))\n",
    "\t\t# \tth = val_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0cd67b78-44b3-4d66-8853-d3279e95062b",
    "_uuid": "336b9ba9-153a-417b-84c5-8d80e5285096",
    "execution": {
     "iopub.status.busy": "2021-06-07T16:40:40.913791Z",
     "iopub.status.idle": "2021-06-07T16:40:40.914172Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# # cv2.imwrite(\"a.jpg\",np.random.random((32,32,3)))\n",
    "# img  = cv2.imread(\"a.jpg\")\n",
    "# print(img.shape)\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5ae4e38f-a102-4eb6-8891-d86647d65ab9",
    "_uuid": "e4190074-1ff3-4a70-a2d4-1870ea78936a",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
